# üó∫Ô∏è Planificaci√≥n ‚Äî Analizador de P√°del

## üöÄ Plan de Implementaci√≥n

### Fase 1: Setup B√°sico (Semanas 1-2)
- [ ] Configurar estructura del proyecto
- [ ] **Dise√±ar especificaci√≥n OpenAPI (API First)**
- [ ] **Configurar Swashbuckle y generar documentaci√≥n Swagger**
- [ ] **Configurar mock server con Prism para frontend**
- [ ] Setup de Docker y docker-compose
- [ ] Configurar base de datos PostgreSQL
- [ ] Crear API b√°sica de videos (siguiendo contrato OpenAPI)
- [ ] Setup de frontend React + TypeScript
- [ ] Configurar CORS y endpoints b√°sicos

### Fase 2: Subida y Almacenamiento (Semanas 3-4)
- [ ] Implementar subida de videos
- [ ] Configurar almacenamiento local (`/uploads`)
- [ ] Crear API endpoints para videos
- [ ] Implementar frontend de subida con drag & drop
- [ ] Implementar procesamiento s√≠ncrono

### Fase 3: Procesamiento de Video (Semanas 5-7)
- [ ] Integrar FFmpeg para extracci√≥n de frames
- [ ] Implementar scripts Python con YOLO v8
- [ ] Integrar detecci√≥n de pelota (OpenCV HSV)
- [ ] Crear servicios modulares de an√°lisis
- [ ] Extraer y guardar estad√≠sticas en BD

### Fase 4: Visualizaci√≥n y UI (Semanas 8-9)
- [ ] Implementar dashboard principal
- [ ] Crear heatmap con D3.js
- [ ] Crear visualizaciones estad√≠sticas con Chart.js
- [ ] Implementar reproductor de video
- [ ] Sistema de descarga de reportes (PDF)

### Fase 5: Testing y Deploy (Semana 10)
- [ ] Testing unitario y de integraci√≥n
- [ ] Optimizaci√≥n de rendimiento
- [ ] Configurar CI/CD (GitHub Actions)
- [ ] Deploy a producci√≥n
- [ ] Documentaci√≥n final

---

## üîß Configuraci√≥n de Desarrollo

### Prerrequisitos

| Herramienta | Versi√≥n | Notas |
|---|---|---|
| .NET SDK | 8.0 | Requerido para desarrollo backend local |
| Node.js | 18+ | Requerido para desarrollo frontend local |
| Docker | Latest | Obligatorio para producci√≥n |
| Docker Compose | Latest | Obligatorio para producci√≥n |
| FFmpeg | Latest | Solo si desarrollas sin Docker |
| Python | 3.10+ | Solo si desarrollas sin Docker |

### Puertos por Entorno

| Servicio | Desarrollo | Producci√≥n |
|---|---|---|
| Frontend | :5173 (Vite Dev Server) | :80 (Nginx) |
| Backend | :5000 (Kestrel directo) | :5000 (interno, via Nginx) |
| PostgreSQL | :5432 | :5432 (interno) |

### Setup Local (Desarrollo)

```bash
# 1. Clonar repositorio
git clone <repo-url>
cd AnalizadorPadel

# 2. Iniciar base de datos
docker-compose up -d postgres

# 3. Backend (http://localhost:5000)
cd backend
dotnet restore
dotnet run

# 4. Frontend (http://localhost:5173)
cd frontend
npm install
npm run dev
```

### Setup con Docker (Producci√≥n)

```bash
# Levantar todos los servicios
docker-compose up -d

# Ver logs
docker-compose logs -f

# La app estar√° disponible en http://localhost
```

### Variables de Entorno

```env
# Backend
ConnectionStrings__DefaultConnection=Host=postgres;Database=padeldb;Username=postgres;Password=postgres
UPLOADS_PATH=/app/uploads
PYTHON_SCRIPTS_PATH=/app/scripts
MAX_VIDEO_SIZE_MB=500
PROCESSING_TIMEOUT_MINUTES=10

# PostgreSQL
POSTGRES_DB=padeldb
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
```

---

## üìù Notas y Decisiones

### Decisiones T√©cnicas Tomadas

| # | Decisi√≥n | Alternativa Considerada | Justificaci√≥n |
|---|---|---|---|
| 1 | React sobre Angular | Angular, Vue | Mayor ecosistema y flexibilidad |
| 2 | PostgreSQL sobre MongoDB | MongoDB, MySQL | Mejor para datos relacionales complejos |
| 3 | .NET sobre Node.js | Node.js, Python FastAPI | Mejor rendimiento para procesamiento pesado |
| 4 | Docker | Bare metal | Facilita deploy y desarrollo consistente |
| 5 | Sin autenticaci√≥n en MVP | JWT desde el inicio | Reduce complejidad, se agrega en V2.0 |
| 6 | Almacenamiento local | AWS S3 | Sin costos de cloud en MVP |
| 7 | Procesamiento s√≠ncrono | Colas con RabbitMQ/Redis | M√°s simple, suficiente para MVP |
| 8 | YOLO v8 via Python subprocess | ONNX Runtime en .NET | M√°s simple, acceso al ecosistema Python/ML |
| 9 | Nginx + Kestrel | Solo Kestrel, IIS | Nginx maneja SSL, archivos est√°ticos y proxy |
| 10 | Debian Slim para backend | Alpine | Compatibilidad con FFmpeg y OpenCV (glibc) |
| 11 | BDD + TDD h√≠brido | Solo TDD | User Stories se traducen directamente a Gherkin |
| 12 | SpecFlow | BDDfy, Machine.Specifications | Mejor integraci√≥n con .NET y Visual Studio |
| 13 | xUnit | NUnit, MSTest | Mejor rendimiento, est√°ndar moderno en .NET |
| 14 | FluentAssertions | Shouldly, Assert | Sintaxis m√°s legible y expresiva |
| 15 | **API First** | Code First | Permite desarrollo paralelo, documentaci√≥n autom√°tica |
| 16 | **Conventional Commits** | Commits libres | Historial ordenado, generaci√≥n de changelogs |
| 17 | **Git Flow** | Trunk-based | Flujo estructurado para releases |
| 18 | **ADRs** | Decisiones no documentadas | Trazabilidad de decisiones arquitect√≥nicas |

### Riesgos Identificados

| Riesgo | Probabilidad | Impacto | Mitigaci√≥n |
|---|---|---|---|
| Procesamiento intensivo en CPU | Alta | Alto | Frame sampling (1/5), timeout de 10 min |
| Baja precisi√≥n en detecci√≥n de pelota | Alta | Medio | Aceptar limitaci√≥n en MVP, TrackNet en V2.0 |
| Videos con √°ngulos no est√°ndar | Media | Alto | Documentar requisitos de grabaci√≥n |
| Costos de almacenamiento | Media | Medio | Local en MVP, S3 en V2.0 |
| Escalabilidad del procesamiento | Baja (MVP) | Alto | Arquitectura modular para migrar a async |

### Limitaciones Conocidas del MVP

- **Detecci√≥n de pelota**: Funciona bien para pelotas de color amarillo/verde con buena iluminaci√≥n. Falla con oclusiones o movimientos muy r√°pidos.
- **√Ångulo de c√°mara**: Se asume grabaci√≥n cenital o semi-cenital est√°ndar. √Ångulos laterales reducen la precisi√≥n.
- **Iluminaci√≥n**: El an√°lisis requiere buena iluminaci√≥n. Canchas bajo techo con mala luz pueden afectar la detecci√≥n.
- **Tama√±o m√°ximo**: 500MB limita videos de alta resoluci√≥n/larga duraci√≥n.
- **Procesamiento s√≠ncrono**: El usuario espera en la misma request. Para videos largos, el timeout del browser puede ser un problema.

---

## üß™ Estrategia de Testing

### Enfoque H√≠brido: BDD + TDD

Se adopta un enfoque h√≠brido que combina Behavior-Driven Development (BDD) para features de usuario y Test-Driven Development (TDD) para l√≥gica de negocio.

| Tipo | Herramienta | Uso |
|------|-------------|-----|
| **BDD** | SpecFlow | Features de usuario (User Stories) |
| **TDD** | xUnit + FluentAssertions | L√≥gica de negocio |
| **Mocking** | Moq | Dependencias en tests unitarios |

### Justificaci√≥n de la Decisi√≥n

| # | Factor | BDD | TDD |
|---|--------|-----|-----|
| 1 | User Stories existentes | ‚úÖ Se traducen directamente a Gherkin | ‚ùå Requiere adaptaci√≥n |
| 2 | Documentaci√≥n viva | ‚úÖ SpecFlow genera docs autom√°ticas | ‚ùå No genera docs |
| 3 | Stakeholders no t√©cnicos | ‚úÖ Gherkin es legible | ‚ùå Requiere conocimiento t√©cnico |
| 4 | Velocidad de desarrollo | ‚ö†Ô∏è Setup inicial m√°s lento | ‚úÖ M√°s r√°pido de iniciar |
| 5 | L√≥gica de negocio compleja | ‚ùå Overkill para unit tests | ‚úÖ Ideal para validaciones |

### Integraci√≥n con el Plan de Implementaci√≥n

| Fase | Actividades de Testing |
|------|----------------------|
| **Fase 1** | Setup de SpecFlow, xUnit, FluentAssertions |
| **Fase 2** | Tests BDD para US-1 (Subida de Videos), Tests TDD para VideoValidationService |
| **Fase 3** | Tests TDD para StatisticsCalculator, HeatmapGenerator |
| **Fase 4** | Tests BDD para US-2, US-3, US-4, US-5 |
| **Fase 5** | Tests de integraci√≥n, CI/CD pipeline |

### Cobertura de Tests por User Story

| User Story | Escenarios BDD | Tests TDD | Prioridad |
|------------|----------------|-----------|-----------|
| US-1: Subir Video | 5 | 8 | Alta |
| US-2: Ver Estad√≠sticas | 5 | 6 | Alta |
| US-3: Descargar PDF | 3 | 2 | Media |
| US-4: Historial | 3 | 4 | Media |
| US-5: Monitorear | 4 | 3 | Alta |

### Estimaci√≥n de Tiempo para Testing

| Actividad | D√≠as | Dependencia |
|-----------|------|-------------|
| Setup SpecFlow + xUnit | 1 | Fase 1 |
| Tests BDD US-1 | 1 | Fase 2 |
| Tests TDD Validadores | 1 | Fase 2 |
| Tests TDD Procesamiento | 2 | Fase 3 |
| Tests BDD US-2 a US-5 | 2 | Fase 4 |
| Tests Integraci√≥n + CI/CD | 1 | Fase 5 |
| **Total** | **8 d√≠as** | |

### Decisi√≥n Documentada

| # | Decisi√≥n | Alternativa Considerada | Justificaci√≥n |
|---|---|---|---|
| 11 | BDD + TDD h√≠brido | Solo TDD | User Stories se traducen directamente a Gherkin |
| 12 | SpecFlow | BDDfy, Machine.Specifications | Mejor integraci√≥n con .NET y Visual Studio |
| 13 | xUnit | NUnit, MSTest | Mejor rendimiento, est√°ndar moderno en .NET |
| 14 | FluentAssertions | Shouldly, Assert | Sintaxis m√°s legible y expresiva |

---

## üî¨ Riesgos T√©cnicos y Spikes de Validaci√≥n

Los spikes son experimentos t√©cnicos cortos (1-2 d√≠as) para validar riesgos antes de invertir semanas en implementaci√≥n.

### Resumen de Riesgos

| Riesgo | Nivel | ¬øBloquea MVP? | Spike |
|---|---|---|---|
| YOLO con baja precisi√≥n en contexto p√°del | üü° Medio | Parcialmente | Spike 1 |
| Mapeo incorrecto pixel ‚Üí cancha real | üü° Medio | No (degraded) | Spike 3 |
| Integraci√≥n .NET ‚Üí Python fr√°gil en Docker | üü° Medio | **S√≠** | Spike 4 |
| Rendimiento s√≠ncrono muy lento | üî¥ Alto | **S√≠** | Diferido |

---

### Spike 1 ‚Äî Validaci√≥n de YOLO en Videos de P√°del
‚è±Ô∏è Estimado: 1-2 d√≠as

**Riesgo que valida**: YOLO v8 est√° entrenado con COCO dataset (personas en contextos generales). El p√°del tiene particularidades:
- C√°mara cenital cambia la forma del cuerpo respecto al training data
- Jugadores con ropa de colores similares al fondo de cancha
- Vidrios de la cancha crean reflejos que confunden el detector
- En partidos con √°rbitro y espectadores visibles, pueden aparecer falsos positivos

**Objetivo**: Confirmar que YOLO v8 detecta correctamente los 4 jugadores en videos reales de p√°del con c√°mara cenital.

**Pasos**:
1. Tomar 3-5 clips de 30 segundos de partidos reales (distintas canchas, iluminaciones, √°ngulos)
2. Correr YOLO v8 nano con un script Python minimal
3. Revisar visualmente los bounding boxes generados
4. Medir: ¬ødetecta 4 jugadores?, ¬øhay falsos positivos?, ¬øse pierde alguno?

**Script m√≠nimo**:
```python
from ultralytics import YOLO
model = YOLO('yolov8n.pt')
results = model('partido_padel.mp4', classes=[0], save=True)
# Revisar el video resultante en runs/detect/
```

**Criterio de √©xito**: Detecci√≥n correcta de los 4 jugadores en > 85% de los frames en condiciones normales de grabaci√≥n.

**Plan B si falla**:
- Probar YOLO v8 medium o large (m√°s preciso, m√°s lento)
- Evaluar fine-tuning con un dataset peque√±o de p√°del (~500 im√°genes etiquetadas)
- Filtrar detecciones por zona de la cancha (ignorar espectadores fuera de los l√≠mites)

---

### Spike 3 ‚Äî Transformaci√≥n de Coordenadas Pixel ‚Üí Cancha
‚è±Ô∏è Estimado: 2 d√≠as

**Riesgo que valida**: Para calcular distancias en metros y generar heatmaps precisos, necesitamos transformar coordenadas de pixel a metros reales de la cancha. Esto requiere detectar las l√≠neas de la cancha, lo cual puede ser dif√≠cil con:
- Sombras sobre las l√≠neas
- C√°maras no perfectamente centradas
- Distorsi√≥n de lente
- Canchas con iluminaci√≥n no uniforme

**Objetivo**: Verificar si podemos detectar las 4 esquinas de la cancha y aplicar una transformaci√≥n homogr√°fica confiable.

**Pasos**:
1. Intentar detectar las l√≠neas de la cancha con OpenCV `HoughLinesP`
2. Identificar las 4 esquinas de la cancha (intersecciones de l√≠neas)
3. Aplicar `cv2.getPerspectiveTransform` para rectificar la vista
4. Transformar posiciones de jugadores a coordenadas de cancha (10m x 20m)
5. Validar que las distancias calculadas sean realistas

**Script de referencia**:
```python
import cv2
import numpy as np

# Puntos detectados en imagen (ejemplo)
src_points = np.float32([[px1,py1],[px2,py2],[px3,py3],[px4,py4]])
# Cancha de p√°del: 10m x 20m (normalizado a pixels)
dst_points = np.float32([[0,0],[640,0],[0,360],[640,360]])

M = cv2.getPerspectiveTransform(src_points, dst_points)
# Aplicar transformaci√≥n a posiciones de jugadores
player_court = cv2.perspectiveTransform(player_pixels, M)
```

**Criterio de √©xito**: Las 4 esquinas de la cancha detectadas con error < 10 pixels en videos de distintas c√°maras y condiciones.

**Plan B si falla**:
- Para MVP: usar coordenadas normalizadas (0.0 - 1.0) en lugar de metros reales
- Pedir al usuario que marque manualmente las 4 esquinas al subir el video
- Asumir un factor de conversi√≥n fijo (pixels/metro) como aproximaci√≥n

---

### Spike 4 ‚Äî Integraci√≥n .NET ‚Üí Python subprocess en Docker
‚è±Ô∏è Estimado: 1 d√≠a

**Riesgo que valida**: La integraci√≥n via subprocess tiene varios riesgos pr√°cticos:
- YOLO carga el modelo completo en RAM (~200MB). Con m√∫ltiples requests simult√°neos puede haber OOM
- Si Python falla, el error puede quedar silenciado y el request queda colgado
- Path management de scripts y modelos dentro del contenedor
- Race conditions con archivos de video en `/uploads`

**Objetivo**: Confirmar que la integraci√≥n funciona en Docker con manejo correcto de errores y requests concurrentes.

**Pasos**:
1. Crear endpoint .NET m√≠nimo que llame a un script Python que cargue YOLO
2. Testear con un video real ‚Üí verificar resultado correcto
3. Simular error Python (script que falla con excepci√≥n) ‚Üí verificar captura en .NET
4. Lanzar 3 requests simult√°neos ‚Üí verificar sin OOM ni deadlocks
5. Medir uso de memoria con YOLO cargado N veces simult√°neamente

**Criterio de √©xito**: Manejo correcto de errores + 3 requests simult√°neos sin OOM ni deadlocks en una m√°quina con 4GB RAM.

**Plan B si falla**:
- Implementar un proceso Python daemon que mantiene YOLO cargado (1 instancia compartida)
- Implementar una cola simple con `SemaphoreSlim` en .NET para limitar a 1 request de procesamiento a la vez
- Considerar FastAPI como servicio interno desde el inicio del MVP

---

### Spike Diferido ‚Äî Benchmark de Rendimiento
‚è±Ô∏è Estimado: 1 d√≠a | Diferido para post-implementaci√≥n inicial

**Cuando ejecutar**: Una vez completados Spike 1 y Spike 4, y antes de comenzar la Fase 3 (procesamiento de video).

**Objetivo**: Medir el tiempo real de procesamiento de un video de 5 minutos en CPU (sin GPU) y decidir si el modelo s√≠ncrono es viable o necesitamos cambiar a as√≠ncrono.

---

*√öltima actualizaci√≥n: 18 de Febrero 2026*
